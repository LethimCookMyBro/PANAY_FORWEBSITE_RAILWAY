import os
import json
import logging
from typing import List, Any, Tuple

from pydantic import Field
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document

from pgvector.psycopg2 import register_vector
import psycopg2  # noqa: F401 (‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö connection_pool)
import numpy as np  # noqa: F401 (‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏ä‡∏ô‡∏¥‡∏î)

# flashrank ‡πÄ‡∏õ‡πá‡∏ô optional ‚Äî ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∞ fallback ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ base score
try:
    from flashrank import Ranker, RerankRequest  # type: ignore
    _FLASHRANK_AVAILABLE = True
except Exception:
    _FLASHRANK_AVAILABLE = False


def _safe_load_json(val):
    """‡∏Ñ‡∏∑‡∏ô dict ‡πÄ‡∏™‡∏°‡∏≠ ‡πÅ‡∏°‡πâ metadata ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠ None"""
    if not val:
        return {}
    if isinstance(val, dict):
        return val
    try:
        return json.loads(val)
    except Exception:
        return {"_raw_meta": str(val)}


def _env_int(key: str, default: int) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except Exception:
        return default


# ===============================
# Base Vector Retriever (pgvector)
# ===============================
class PostgresVectorRetriever(BaseRetriever):
    """
    ‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á documents (pgvector)
    - ‡πÉ‡∏ä‡πâ connection_pool (psycopg2.pool) ‡∏ó‡∏µ‡πà main.py ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ
    - register_vector(conn) ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô query
    - ‡∏Ñ‡∏∑‡∏ô list[Document] ‡∏û‡∏£‡πâ‡∏≠‡∏° metadata['distance']
    """
    connection_pool: Any = Field(...)
    embedder: Any = Field(...)
    collection: str = Field(default="plcnext")
    limit: int = Field(default_factory=lambda: _env_int("RETRIEVE_LIMIT", 50))

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # embedder ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (SentenceTransformer) ‡∏Ñ‡∏∑‡∏ô numpy.ndarray
        query_vector = self.embedder.encode(query)

        conn = self.connection_pool.getconn()
        try:
            register_vector(conn)
            with conn.cursor() as cur:
                cur.execute(
                    """
                    SELECT content, metadata, embedding <-> %s AS distance
                    FROM documents
                    WHERE collection = %s
                    ORDER BY embedding <-> %s
                    LIMIT %s
                    """,
                    (query_vector, self.collection, query_vector, self.limit),
                )
                rows = cur.fetchall()

            docs: List[Document] = []
            for content, metadata, distance in rows:
                meta = _safe_load_json(metadata)
                meta["distance"] = float(distance)
                docs.append(Document(page_content=content, metadata=meta))
            return docs

        except Exception as e:
            logging.error("üî• Error in PostgresVectorRetriever: %s", e, exc_info=True)
            return []
        finally:
            self.connection_pool.putconn(conn)


# ===============================
# Flashrank-based Reranker
# ===============================
class EnhancedFlashrankRerankRetriever(BaseRetriever):
    """
    ‡∏Ç‡∏±‡πâ‡∏ô rerank (lexical+semantic) ‡∏î‡πâ‡∏ß‡∏¢ Flashrank ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏ß‡∏Å domain-boost
    - base_retriever: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏´‡∏≤ candidates ‡∏Å‡πà‡∏≠‡∏ô
    - top_n: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (env: RERANK_TOPN)
    - ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏Ñ‡∏ô‡∏î‡∏¥‡πÄ‡∏î‡∏ï‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ Flashrank ‡∏î‡πâ‡∏ß‡∏¢ env: RERANK_CANDIDATES_MAX (‡∏î‡∏µ‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß)
    """
    base_retriever: BaseRetriever = Field(...)
    top_n: int = Field(default_factory=lambda: _env_int("RERANK_TOPN", 8))

    # ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏î‡πÄ‡∏°‡∏ô (boost)
    _PLC_TERMS = [
        "plcnext", "phoenix contact", "gds", "esm", "profinet", "axc f",
        "axc f 2152", "axc f 3152", "axc f 1152", "plcnext engineer"
    ]
    _PROTO_TERMS = [
        "protocol", "mode", "rs-485", "rs485", "profinet", "ethernet",
        "serial", "communication", "modbus", "tcp", "udp", "interface",
        "opcua", "opc ua"
    ]

    def _rank(self, query: str, docs: List[Document]) -> List[Tuple[float, Document]]:
        # 1) ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å Flashrank (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ) ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ 1 - distance ‡πÄ‡∏õ‡πá‡∏ô similarity
        if _FLASHRANK_AVAILABLE:
            try:
                ranker = Ranker(model_name="ms-marco-MiniLM-L-12-v2", cache_dir="/app/models")
                passages = [{"id": i, "text": d.page_content} for i, d in enumerate(docs)]
                req = RerankRequest(query=query, passages=passages)
                result = ranker.rerank(req)
                # ‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏Ç‡∏≠‡∏á flashrank ‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô "id/score" ‡∏´‡∏£‡∏∑‡∏≠ "index/relevance_score"
                pairs: List[Tuple[float, Document]] = []
                for it in result:
                    idx = int(it.get("id", it.get("index")))
                    sc = float(it.get("score", it.get("relevance_score")))
                    pairs.append((sc, docs[idx]))
            except Exception as e:
                logging.warning("‚ö†Ô∏è Flashrank failed, fallback to base scores: %s", e)
                pairs = [(1.0 - float(d.metadata.get("distance", 1.0)), d) for d in docs]
        else:
            pairs = [(1.0 - float(d.metadata.get("distance", 1.0)), d) for d in docs]

        # 2) domain-boost (‡∏ô‡∏∏‡πà‡∏°‡∏•‡∏á + capped)
        boosted: List[Tuple[float, Document]] = []
        q_tokens = (query or "").lower().split()
        for s, d in pairs:
            text_low = (d.page_content or "").lower()
            bonus = 0.0
            if any(w in text_low for w in self._PLC_TERMS):
                bonus += 0.10
            if any(tok in text_low for tok in q_tokens if tok and len(tok) > 2):
                bonus += 0.20
            proto_hits = sum(1 for t in self._PROTO_TERMS if t in text_low)
            if proto_hits > 0:
                bonus += min(0.30, proto_hits * 0.08)  # cap 0.30
            ctype = (d.metadata or {}).get("chunk_type")
            if ctype == "golden_qa":
                bonus += 10.0
            elif ctype == "spec_pair":
                bonus += 0.15
            boosted.append((s + bonus, d))

        boosted.sort(key=lambda x: x[0], reverse=True)
        return boosted

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # ‚úÖ ‡πÅ‡∏Å‡πâ‡∏à‡∏≤‡∏Å get_relevant_documents ‡πÄ‡∏õ‡πá‡∏ô invoke
        cand = self.base_retriever.invoke(query) or []
        if not cand:
            return []
        # ‚úÖ ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ Flashrank ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß/‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
        cap = _env_int("RERANK_CANDIDATES_MAX", 32)
        ranked = self._rank(query, cand[:cap])
        
        # Store score in metadata
        results = []
        for score, doc in ranked[:self.top_n]:
            doc.metadata["score"] = score
            results.append(doc)
        return results


# ===============================
# No-op Reranker (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö A/B test)
# ===============================
class NoRerankRetriever(BaseRetriever):
    """
    ‡πÑ‡∏°‡πà‡∏ó‡∏≥ rerank ‡πÉ‡∏î ‡πÜ ‚Äî ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏à‡∏≤‡∏Å base_retriever ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏±‡∏î Top-N
    """
    base_retriever: BaseRetriever = Field(...)
    top_n: int = Field(default=8)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # ‚úÖ ‡πÅ‡∏Å‡πâ‡∏à‡∏≤‡∏Å get_relevant_documents ‡πÄ‡∏õ‡πá‡∏ô invoke
        docs = self.base_retriever.invoke(query) or []
        return docs[: self.top_n]